---
layout: post
title: 论文翻译
categories: translation CNN 
tag: classify
---

# 《On Classification of Distorted Images with Deep Convolutional Neural Networks》翻译
原文地址：[https://arxiv.org/pdf/1701.01924](https://arxiv.org/pdf/1701.01924)

# 基于深度卷积神经网络的畸变图像分类

## 摘要
图像模糊和图像噪声是图像采集过程中常见的失真。 在本文中，我们系统地研究了图像失真对深度神经网络（DNN）图像分类器的影响。 首先，我们研究了四种类型扭曲下的DNN分类器性能。 其次，我们提出了两种方法来减轻图像失真的影响：重新训练和噪声图像的微调。 我们的研究结果表明，在一定条件下，噪声图像的微调可以减少由于输入的扭曲所产生的很大影响，比再训练更实用。
索引条款 - 图像模糊; 图像噪声; 深度卷积神经网络;再训练; 微调

## 1. 引言
近来，深层神经网络（DNN）在许多计算机视觉任务中取得了较好的成果[1]。在图像分类中，像以前的手工制作的功能，像Alexnet [2]这样的DNN方法显着提高了准确度。 DNN的进一步工作[3,4]继续推进DNN结构，提高性能。  
在实际应用中，捕获的图像中可能会出现各种类型的失真。例如，用移动摄像机拍摄的图像可能会受到运动模糊的影响。在本文中，我们系统地研究了图像失真对基于DNN的图像分类器的影响。我们还研究了一些减轻图像失真对分类精度的影响的策略。  
图像失真的两大类是图像模糊和图像噪声[5]。它们是由图像采集过程中的各种问题引起的。例如，当相机失焦时会出现散焦模糊。运动模糊是由相机和视图之间的相对运动引起的，这对于基于智能手机的图像分析是常见的[6,7,8]。图像噪声通常是由于照明和/或高温不良引起的，这会降低相机内的电荷耦合器件（CCD）的性能。  
当在实际应用中应用DNN分类器时，可能在输入图像中出现一些图像模糊和噪声。这些降级将影响DNN分类器的性能。我们的工作为这个问题做了很多贡献。首先，我们研究图像失真对DNN分类器的影响。我们在输入图像上检查四种类型的失真下的DNN分类器性能：运动模糊，散焦模糊，高斯噪声以及它们的组合。其次，我们研究两种方法来减轻图像失真的影响。在一种方法中，我们用嘈杂的图像重新整理网络。我们发现，这种方法可以提高分类失真图像时的准确性。然而，重新训练需要大量的训练数据集用于非常深入的网络。灵感来自[9]，在另一种方法中，我们用失真的图像微调网络的前几层。本质上，我们调整DNN的低电平滤波器以匹配失真图像的特性。  
一些以前的作品已经研究了图像失真的影响[10]。关注DNN，Basu et al。 [11]提出了一种从深层信念网修改的新模式来处理嘈杂的投入。他们在一个叫做n-MNIST的噪声数据集上报告了很好的结果，它与原始的MNIST数据集相比包含高斯噪声，运动模糊和降低的对比度。最近，Dodge和Karam [12]报道了由于多个DNN中的各种图像失真导致的退化。与这些作品相比，我们进行统一的研究，研究图像失真对（i）手写数字分类和（ii）自然图像分类的影响。此外，我们检查使用再现和微调与嘈杂的图像，以减轻影响。  
在“干净”图像的分类（即没有失真）中，一些以前的工作已经尝试对训练数据引入噪声[13,14]。在这些作品中，他们的目的是使用噪音来规范模型，以防止在训练过程中过度使用。相反，我们的目标是了解使用噪声训练数据在失真图像分类中的好处。我们的研究结果还表明，在某些条件下，使用嘈杂图像进行微调可以是一种有效和实用的方法。  

## 2. 深层建筑
在本节中，我们简要介绍深层神经网络（DNN）的思想。 DNN有很多类型，我们主要介绍深层卷积神经网络（DCNN），DNN的详细介绍可以在[15]中找到。
DNN是一种受人类中枢神经系统启发的机器学习架构。 DNN的基本元素是神经元。在DNN中，邻域层被神经元完全连接，一个DNN可以具有多个级联层。那些层一起形成一个DNN。
DNN在小图像上的问题上取得了很好的表现[16]。然而，对于大图像的问题，常规DNN需要使用上一层中的所有节点作为下一层的输入，这导致具有非常大数量参数的模型，并且不可能用有限的数据集训练，计算来源卷积神经网络（CNN）的想法是利用图像的本地连通性作为先验知识，即节点仅连接到上一层的邻域节点。该约束显着减小了模型的大小，同时保留了图像中的必要信息。
对于卷积层，每个节点连接到输入层中的局部区域，称为接收场。所有这些节点形成一个输出层。对于输出层中的所有这些节点，它们具有不同的内核，但在计算激活功能时它们共享相同的权重。
图1显示了LeNet-5的架构，用于MNIST数据集上的数字图像分类[17]。从图中可以看出，该模型具有两个卷积层及其对应的池层。这是模型的卷积部分。以下两层是平坦的和完全连接的层，这些层是从常规DNN继承的。

## 3. 实验设置
我们对相对较小的数据集[17,18]和大型图像数据集ImageNet [19]进行实验。我们在一些小数据集上检查不同的完整训练/微调配置，以了解其有效性。然后，我们检查并验证ImageNet数据集上的方法。  
我们使用MatConvNet [20]进行实验，MatConvNet是可以运行和学习卷积神经网络的MATLAB工具箱。所有的实验都是在带有Intel Xeon E5-2630 CPU的Dell T5610 WorkStation上进行的。  
深层架构和数据集：在本评估中，我们考虑了三个知名数据集：MNIST [17]，CIFAR-10 [18]和ImageNet [19]。  
MNIST是一个手写数字数据集，具有60000个训练图像和10000个测试图像。每个图像是28×28灰度图像，属于从0到9的一个数字级别。对于MNIST，我们使用LeNet-5 [17]进行分类。我们使用的LeNet-5的结构如图1所示。该网络有6层，其中4个具有训练参数：前两个卷积层，扁平化和完全连接层。  
我们考虑采用两种处理扭曲图像的方法：使用嘈杂的图像进行精细化和重新训练。  
在微调中，我们从使用原始数据集训练的预先训练的模型（即没有失真的图像）开始。我们在一个失真的数据集上微调模型的前N层，同时将参数固定在剩余的层中。在最后一层中修复参数的原因是，图像模糊和噪声被认为对图像中的低级特征（如颜色，边缘和纹理特征）具有更大的影响。然而，这些扭曲对高级信息，如图像的语义意义[21]几乎没有影响。因此，在微调中，我们关注的是DNN的起始层，其中包含更多的低层信息。例如，对于LeNet-5，我们有4层参数，这意味着N的范围从1到4.我们将微调方法表示为前1到第4。  
在重新训练中，我们从头开始训练整个网络的扭曲数据集，不要使用预先训练的模型。我们将再训练方法表示为重新训练。  
为了重新训练LeNet-5，我们将学习率设置为10 ^ -3，将时期的数量设置为20.对于微调，我们将学习率设置为10 ^ -5（重新训练学习的1％速率），时代数为15.每个时期大约需要1分钟，所以训练过程需要大约20分钟进行重新训练，15分钟进行微调。  
CIFAR-10数据集由10个类的60000个32×32彩色图像组成，每个类有6000个图像。 50000是训练图像，10000是测试图像。为了使训练更快，我们使用MatConvNet [20]提供的快速模型。 CIFAR10快速模型的结构如图2所示。  
与MNIST以前的方法类似，我们对CIFAR失真数据集使用微调和重新训练。在CIFAR10-quick模型中有5层参数，所以我们有第一到第五的微调方法。重新训练方法被表示为再培训。  
对于重新训练CIFAR10-quick，我们将时期的数量设置为45.前30个时期的学习速率设置为5×10-2，后10个时期的5×10-2，5×10-4最后5个纪元。对于微调，我们将时代的数量设置为30.前25个时期的学习率为5×10-4，最后5个时期的学习率为5×10-5。每个纪元大约需要3分钟，所以培训过程需要135分钟的时间再进行训练，90分钟进行微调。  
在这里，我们还提出了对ILSVRC2012数据集的评估。 ILSVRC2012 [22]是一个大型自然图像数据集，包含1000多个类别的超过一百万张图像。图像和类别选自ImageNet [19]。为了了解有限数据在许多应用中的影响，我们从培训数据集中随机选择50000张图像进行训练，并使用包含50000张图像的ILSVRC2012验证集进行测试。  
我们使用经过预训练的Alexnet模型的ILSVRC2012验证集的微调方法[2]。我们在这里不使用再培训方法，因为仅使用ILSVRC2012训练集的一小部分来重新训练Alexnet会引起过度配对。我们微调Alexnet的前3层，同时修复剩余的层。对于飞行过程，历元的数量设置为20.学习速率从时代1到时期20设置为10-8到10-10，减小了对数空间。我们也使用5×10-4的重量衰减。每个纪元的大概训练时间为90分钟，总计过程为30小时。  
关于计算时间，微调比在MNIST和CIFAR-10数据集上重新训练所需的时间少。对于ILSVRC2012验证集，我们还需要使用微调方法来防止过度拟合。  
模糊和噪声的类型：在本实验中，我们考虑两种模糊：运动模糊和散焦模糊，以及一种类型的噪声：高斯噪声。  
运动模糊是通常由相机抖动和/或拍摄对象的快速移动引起的典型模糊类型。我们使用随机游走生成运动模糊核心[23]。对于每个步长，我们将运动模糊核随机移动1像素。运动模糊核的大小从[0,4]中采样。  
当相机失去图像的焦点时，会发生散焦模糊。我们通过统一的抗锯齿光盘产生散焦模糊。从[0,4]采样盘的半径。  
在为一个图像生成动画或散焦模糊内核之后，我们使用该内核对整个图像进行卷积运算，以生成模糊图像。  
高斯噪声是由较差的照明和/或高温引起的，这可以防止相机中的CCD获得正确的像素值。我们选择具有零均值的高斯噪声，并且在[0,255]中具有整数值的彩色图像上从[0,4]采样的标准偏差σ。  
最后，我们考虑所有上述三种失真的组合。每个噪声的值分别从[0,4]采样。  
图3和图4分别示出了MNIST和CIFAR-10中的模糊和噪声效应的示例图像。每行图像表示一种类型的失真。对于前3行，仅应用一种类型的失真，对于最后一行，我们将所有3种类型的失真应用于一个图像上。当我们从左到右看到每一行时，失真级别从0增加到4。  
图5显示了ILSVRC2012验证集中的一个例子。当我们生成失真的数据集时，训练和测试集中的每个图像对于所有3种类型的失真都有[0,4]采样的随机失真值。  

## 4. 实验结果和分析
图6和7显示了我们的实验结果。我们比较3种方法：没有训练意味着模型是在干净的数据集上训练的，而在嘈杂的数据集上进行测试。第一-N意味着我们在固定网络中的剩余层时，对前N个层进行微调。对于LeNet-5网络，有4个可培训层，所以我们有CIFAR10快速网络的第一到第四，我们有第一到第五。  
MNIST的结果：图6显示了MNIST数据集的结果。对于运动模糊和高斯噪声，失真的效果相对较小（注意不同图的尺度不同）。散焦模糊和组合噪声对错误率有更多影响。该结果与图3的观察结果一致，运动模糊和高斯噪声图像比散焦模糊和组合噪声更可识别。 MNIST数据集包含具有手写笔画的灰度图像，因此沿笔画的边缘是重要的特征。在我们的实验中，散焦模糊之后的笔画覆盖了更广泛的区域，同时削弱了边缘信息。运动模糊也削弱边缘信息，但不如散焦模糊那么严重。这是因为在相同的参数下，运动模糊的区域小于散焦模糊。高斯噪声对边缘信息的影响有限，所以误码率几乎没有增加。组合噪声对误码率有很大的影响。  
微调和重新训练两种方法都可以显着降低错误率。前3个和第4个结果具有非常相似的结果，表明失真对最后几层影响不大。当失真小的时候，通过重新训练，通过前3和4进行微调可以获得可比的结果。当失真水平增加时，重新训练达到更好的结果。  
CIFAR-10上的结果：从图4可以看出，CIFAR-10中的失真不仅影响边缘信息，而且还对颜色和纹理信息有影响。因此，所有3种类型的失真都可能使图像难以识别。这与图7所示的结果一致。与MNIST数据集的结果不同，所有3种失真都显着恶化了无列车结果的误码率。  
使用微调和重新训练方法都可以显着降低错误率。前3〜第5给出类似的结果，表明失真主要影响前3层。当失真水平低时，微调和再训练也有类似的结果。然而，当失真水平高或混合噪声时，再训练比微调更好。  
从这两个数字可以看出，当我们调整前3层时，结果与微网整体非常相似。该结果表明图像失真对图像的低级信息影响较大，而对高级信息影响不大。  
分析：为了获得有关失真数据的重新训练和重新训练的有效性，我们研究了模型中特征图的统计。受[24]的启发，我们发现图像梯度幅度的均值方差是一个有用的特征。我们不计算图像渐变，而是计算特征图的渐变。然后，我们计算特征图梯度幅度的平均方差。  
给定一个特征图fm作为输入，我们首先使用Sobel滤波器沿水平（x）和垂直方向计算梯度  
************************************
那么我们在位置（m，n）处的fm的梯度幅度为  
********************************************************
在我们对特征映射fm有梯度gfm后，我们计算梯度幅度的方差：vfm = var（gfm）。  
当在图像上应用散焦模糊或运动模糊时，清晰的边缘被模糊化为平滑的边缘，因此梯度幅度图变得平滑，并且具有较低的方差。具有较高梯度方差值vfm的特征图被认为具有更多的边缘和纹理信息，因此更有助于图像表示。而较低的vfm值表明特征映射内的信息是有限的，因此对于图像表示来说是不够的。  
图8显示了CIFAR10-quick模型的conv3层（最后一个交换层）的特征图梯度幅度的均值方差。从这两幅图中我们可以看到：（1）在失真图像上应用原始模型时，与在原始图像上应用模型相比，平均方差减小（见无序列），这表明边缘或纹理信息由于失真而丢失。 （2）对失真图像采用微调方法时，均值方差与原始图像保持类似，表明通过对失真图像进行微调，模型可以从失真图像中提取有用信息。 （3）对于失真图像应用再培训方法，平均方差高于原始图像上的模型。这意味着，再培训的模型适合扭曲的图像数据集。这些结果表明，当我们对失真图像上的模型进行微调时，我们试图使失真图像的特征映射表示接近原始图像，使得失真图像上的分类结果可以接近原始图像的结果。当我们在失真图像上重新训练模型时，我们尝试在失真的数据集上拟合DNN模型，并且特征图表示不一定接近原始图像的表示。  
Imagenet上的结果：我们还研究了对大型数据集和非常深的网络进行微调的效率。对于ILSVRC2012的训练和验证集的实验，我们通过组合所有3种类型的模糊/噪声来产生失真的数据。对于每个图像，对于每种类型的失真，失真水平从[0，4]均匀采样。获得失真的数据后，我们调整了预先训练的Alexnet模型的前3层[2]。表1显示了原先预先训练的Alexnet模型与微调模型之间的准确性比较。与原始预培训模型相比，微调模型提高了失真数据的性能，同时保持了干净数据的性能。当我们想在有限的和失真的数据集上使用像Alexnet这样的大DNN模型时，在前几个层上进行微调可以提高失真数据的模型精度，同时保持清晰数据的准确性。  

## 5. 结论
使用噪声数据对模型进行微调和重新训练可以提高失真数据的模型性能，重新训练方法通常可以达到与微调相比或更好的精度。 但是，我们需要考虑的问题有：  
•失真数据集的大小：如果模型非常深并且失真数据集的大小很小，那么在有限数据集上训练模型会导致过度拟合。 在这种情况下，我们可以通过第一个N层对模型进行微调，同时固定剩余的层以防止过拟合。  
•噪声失真度：当失真度较高时，对失真数据重新训练效果较好。 当失真度较低时，再训练和微调都可以取得较好的效果。 在这种情况下，微调是最好的，因为它更快地收敛，这意味着更少的计算时间，并且适用于尺寸有限的失真数据集。  